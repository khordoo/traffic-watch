{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import requests\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scoring_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scoring_service.py\n",
    "import json\n",
    "import psycopg2\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from dateutil import tz\n",
    "from dateutil.parser import parse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from azureml.core.model import Model\n",
    "from azureml.contrib.services.aml_response import AMLResponse\n",
    "\n",
    "\n",
    "HOST = '34.221.143.98'\n",
    "DATABASE = 'azure_ai'\n",
    "USERNAME = 'postgres'\n",
    "PASSWORD = 'postgres'\n",
    "TIME_SHIFT_STEPS = 24 * 4\n",
    "CAMERA_ID = 76\n",
    "PREDICTION_STEPS = 24 * 4  # one day 15 min intervals\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model,scaler,database,prediction_serivce \n",
    "    model_path = Model.get_model_path('traffic-prediction-cam-76' ,version=3)\n",
    "    model = load_model(model_path + '/model.h5',custom_objects={\"adam\": tf.keras.optimizers.Adam ,\"mae\":tf.keras.losses.mean_absolute_error})\n",
    "    model.compile(optimizer='adam' ,loss='mae')\n",
    "    scaler = joblib.load(model_path + '/scaler.joblib')\n",
    "    database = Database(HOST, DATABASE, USERNAME, PASSWORD)\n",
    "    prediction_serivce = Prediction(database,model,scaler, TIME_SHIFT_STEPS)\n",
    "  \n",
    "\n",
    "        # Handle requests to the service\n",
    "def run(data):\n",
    "    try:\n",
    "        data=json.loads(data)\n",
    "\n",
    "        predictions = prediction_serivce.predict(data['cameraId'], data['steps'])\n",
    "        response=AMLResponse(predictions,200)\n",
    "        response.headers['Access-Control-Allow-Origin']='*'\n",
    "        return predictions\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error\n",
    "    \n",
    "\n",
    "class Database:\n",
    "    def __init__(self, host, database, username, password):\n",
    "        try:\n",
    "            conn = psycopg2.connect(host=host, database=database, user=username, password=password)\n",
    "            self.cursor = conn.cursor()\n",
    "        except Exception as err:\n",
    "            print(f'Failed to connect to Postgres database: {err}')\n",
    "\n",
    "    def fetch_recent_history(self, camera_id, number_of_records, aggregation_minutes_interval=15):\n",
    "        \"\"\"Fetches the  top {} most recent records for the {entity} from the database\"\"\"\n",
    "        query = f\"SELECT   date_trunc('hour', time) + (((date_part('minute', time)::integer / {aggregation_minutes_interval}::integer) * {aggregation_minutes_interval}::integer) || ' minutes')::interval AS time_interval, \" \\\n",
    "                f\"avg(count) FROM public.count where camera_id={camera_id} and label in ('car','bus','truck')  GROUP BY time_interval order by time_interval desc   limit {number_of_records};\"\n",
    "        self.cursor.execute(query)\n",
    "        return self.cursor.fetchall()\n",
    "\n",
    "\n",
    "class Prediction:\n",
    "    def __init__(self, database,model,scaler, history_time_steps):\n",
    "        self.database = database\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.TIME_SHIFT_STEPS = history_time_steps\n",
    "        self.TIME_INTERVALS = timedelta(minutes=15)\n",
    "        self.TIME_ZONES = 'America/Edmonton'\n",
    "\n",
    "    def predict(self, camera_id, prediction_steps):\n",
    "        inputs, historical_dates = self._prepare_inputs(camera_id, self.TIME_SHIFT_STEPS)\n",
    "        X_train_hourOfDay_pred, X_train_dayOfWeek_pred, X_train_dayOfYear_pred, X_train_pred = inputs\n",
    "        prediction_dates = self.create_dates(historical_dates, prediction_steps)\n",
    "        predictions = []\n",
    "        for i in range(prediction_steps):\n",
    "            prediction = self.model.predict([X_train_hourOfDay_pred, X_train_dayOfWeek_pred, X_train_dayOfYear_pred,\n",
    "                                             X_train_pred[:, :, :TIME_SHIFT_STEPS]])\n",
    "            predictions.append(self.scaler.inverse_transform(prediction)[0][0])\n",
    "            X_train_pred = np.insert(X_train_pred, 0, prediction[0][0], axis=2)\n",
    "        \n",
    "        pred_response = []\n",
    "        for date, prediction in zip(prediction_dates, predictions):\n",
    "            pred_response.append({\"time\": date.isoformat(), \"count\": float(prediction)})\n",
    "        historical_hourly = self.get_hourly_historical(camera_id, 24)\n",
    "        return {\"prediction\": pred_response, \"historical\": historical_hourly}\n",
    "\n",
    "    def _prepare_inputs(self, camera_id, steps):\n",
    "        records = self.database.fetch_recent_history(camera_id, 2 * self.TIME_SHIFT_STEPS)\n",
    "        historical = pd.DataFrame(records, columns=['phenomenonTime', 'result'])\n",
    "        historical['result'] = historical['result'].astype(float)\n",
    "        historical.set_index(pd.DatetimeIndex(historical['phenomenonTime']), inplace=True)\n",
    "        historical.drop(['phenomenonTime'], inplace=True, axis=1)\n",
    "\n",
    "        historical[['result']] = self.scaler.transform(historical['result'].values.reshape(-1, 1))\n",
    "        print(historical.head())\n",
    "        train_pred, y_train_pred = self.get_timeseries(historical.copy(), self.TIME_SHIFT_STEPS, 'result')\n",
    "       \n",
    "        # Training\n",
    "        data = historical.copy()\n",
    "        data.drop(['result'], inplace=True, axis=1)\n",
    "        data['hourOfDay'] = data.index.hour\n",
    "        data['dayOfWeek'] = data.index.dayofweek\n",
    "        data['dayOfYear'] = data.index.dayofyear\n",
    "        train_cat_pred = self.get_categorical(data, self.TIME_SHIFT_STEPS)\n",
    "        x_train_pred = np.array(train_pred['result_merged'].values.tolist()[0]).reshape(-1, 1, self.TIME_SHIFT_STEPS)\n",
    "        x_train_hourOfDay_pred = np.array(train_cat_pred['hourOfDay_merged'].values.tolist()[0]).reshape(-1,\n",
    "                                                                                                         self.TIME_SHIFT_STEPS)\n",
    "        x_train_dayOfWeek_pred = np.array(train_cat_pred['dayOfWeek_merged'].values.tolist()[0]).reshape(-1,\n",
    "                                                                                                         self.TIME_SHIFT_STEPS)\n",
    "        x_train_dayOfYear_pred = np.array(train_cat_pred['dayOfYear_merged'].values.tolist()[0]).reshape(-1,\n",
    "                                                                                                         self.TIME_SHIFT_STEPS)\n",
    "        return [x_train_hourOfDay_pred, x_train_dayOfWeek_pred, x_train_dayOfYear_pred, x_train_pred], train_pred.index\n",
    "\n",
    "    def get_timeseries(self, data, steps, target_column):\n",
    "        y = None\n",
    "        df = None\n",
    "        for column in data.columns.tolist():\n",
    "            df = data[[column]].copy()\n",
    "            for i in range(1, steps + 1):\n",
    "                df[f'{column}{i}'] = df[column].shift(-i)\n",
    "            df.dropna(inplace=True, axis=0)\n",
    "\n",
    "            if column == target_column:\n",
    "                y = df[f'{column}{steps}'].values\n",
    "            df.drop([f'{column}{steps}'], inplace=True, axis=1)\n",
    "            df[f'{column}_merged'] = df.values.tolist()\n",
    "            df.drop([f'{column}'], inplace=True, axis=1)\n",
    "            for i in range(1, steps):\n",
    "                df.drop([f'{column}{i}'], inplace=True, axis=1)\n",
    "\n",
    "        return df, y\n",
    "\n",
    "    def get_categorical(self, data, steps):\n",
    "        merged = None\n",
    "        for column in data.columns.tolist():\n",
    "            df = data[[column]]\n",
    "            for i in range(1, steps + 1):\n",
    "                df[f'{column}{i}'] = df[column].shift(-i)\n",
    "            df.dropna(inplace=True, axis=0)\n",
    "            df.drop([f'{column}{steps}'], inplace=True, axis=1)\n",
    "            df[f'{column}_merged'] = df.values.tolist()\n",
    "            df.drop([f'{column}'], inplace=True, axis=1)\n",
    "            for i in range(1, steps):\n",
    "                df.drop([f'{column}{i}'], inplace=True, axis=1)\n",
    "\n",
    "            if merged is None:\n",
    "                merged = df.copy()\n",
    "            else:\n",
    "                merged[f'{column}_merged'] = df[[f'{column}_merged']]\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def create_dates(self, hist_dates, prediction_steps):\n",
    "        most_recent_date = hist_dates[0]\n",
    "        most_recent_date = most_recent_date.replace(tzinfo=tz.gettz(self.TIME_ZONES))\n",
    "        pred_dates = []\n",
    "        for i in range(1, prediction_steps + 1):\n",
    "            pred_dates.append(most_recent_date + i * self.TIME_INTERVALS)\n",
    "        return pred_dates \n",
    "    \n",
    "    def get_hourly_historical(self, camera_id, limit=24):\n",
    "        records = self.database.fetch_recent_history(camera_id=camera_id, number_of_records=limit,\n",
    "                                                     aggregation_minutes_interval=60)\n",
    "        records = [\n",
    "            {'time': record[0].replace(tzinfo=tz.gettz(self.TIME_ZONES)).isoformat(), 'count': float(record[1])}\n",
    "            for record in records]\n",
    "        return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    subscription_id = \"979884b7-8494-4a3d-abd7-e9e63d1f5d90\"  \n",
    "    resource_group = \"azure-ai-hackathon-ml\"  \n",
    "    workspace_name = \"azure-ai-hackathon-ws\"  \n",
    "    workspace_region = \"West US 2\"  \n",
    "   \n",
    "    interactive_auth = InteractiveLoginAuthentication()\n",
    "    ws = Workspace.get(\n",
    "        name=workspace_name,\n",
    "        subscription_id=subscription_id,\n",
    "        resource_group=resource_group,\n",
    "        auth=interactive_auth\n",
    "    )\n",
    "    return ws\n",
    "\n",
    "def get_environment():\n",
    "    environment = Environment(\"LocalDeploy\")\n",
    "    conda_dep = CondaDependencies()\n",
    "    conda_dep.add_pip_package(\"absl-py\")\n",
    "    conda_dep.add_pip_package(\"astor\")\n",
    "    conda_dep.add_pip_package(\"cycler\")\n",
    "    conda_dep.add_pip_package(\"gast\")\n",
    "    conda_dep.add_pip_package(\"google-pasta\")\n",
    "    conda_dep.add_pip_package(\"grpcio\")\n",
    "    conda_dep.add_pip_package(\"h5py\")\n",
    "    conda_dep.add_pip_package(\"joblib\")\n",
    "    conda_dep.add_pip_package(\"Keras-Applications\")\n",
    "    conda_dep.add_pip_package(\"Keras-Preprocessing\")\n",
    "    conda_dep.add_pip_package(\"kiwisolver\")\n",
    "    conda_dep.add_pip_package(\"Markdown\")\n",
    "    conda_dep.add_pip_package(\"matplotlib\")\n",
    "    conda_dep.add_pip_package(\"numpy\")\n",
    "    conda_dep.add_pip_package(\"pandas\")\n",
    "    conda_dep.add_pip_package(\"protobuf\")\n",
    "    conda_dep.add_pip_package(\"pyparsing\")\n",
    "    conda_dep.add_pip_package(\"psycopg2-binary\")\n",
    "    conda_dep.add_pip_package(\"python-dateutil\")\n",
    "    conda_dep.add_pip_package(\"pytz\")\n",
    "    conda_dep.add_pip_package(\"scikit-learn\")\n",
    "    conda_dep.add_pip_package(\"scipy\")\n",
    "    conda_dep.add_pip_package(\"six\")\n",
    "    conda_dep.add_pip_package(\"tb-nightly==1.14.0a20190603\")\n",
    "    conda_dep.add_pip_package(\"tensorflow==2.0.0b1\")\n",
    "    conda_dep.add_pip_package(\"termcolor\")\n",
    "    conda_dep.add_pip_package(\"tf-estimator-nightly==1.14.0.dev2019060501\")\n",
    "    conda_dep.add_pip_package(\"Werkzeug\")\n",
    "    conda_dep.add_pip_package(\"wrapt\")\n",
    "    conda_dep.add_pip_package(\"azureml-core\")\n",
    "    conda_dep.add_pip_package(\"azureml-contrib-services\")\n",
    "\n",
    "    environment.python.conda_dependencies = conda_dep\n",
    "    return environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = initialize()\n",
    "environment = get_environment()\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "                                   environment=environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_local():\n",
    "    deployment_config = LocalWebservice.deploy_configuration()\n",
    "    model = Model(name='traffic-prediction-cam-76', workspace=ws, version=3)\n",
    "    local_service = Model.deploy(ws, \"local-deploy\", [model], inference_config, deployment_config)\n",
    "    local_service.wait_for_deployment()\n",
    "\n",
    "def deploy_to_cloud():\n",
    "    deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "    model = Model(name='traffic-prediction-cam-76', workspace=ws, version=3)\n",
    "    aci_service_name = 'traffic-pred-cam-service'\n",
    "    try:\n",
    "        service = Webservice(ws, name=aci_service_name)\n",
    "        if service:\n",
    "            service.delete()\n",
    "    except WebserviceException as err:\n",
    "        print(err)\n",
    "\n",
    "    service = Model.deploy(ws, aci_service_name, [model, tokenizer, label_encoder], inference_config, deployment_config)\n",
    "\n",
    "    service.wait_for_deployment(True)\n",
    "    print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model traffic-prediction-cam-76:3 to /tmp/azureml_jxkq5b4p/traffic-prediction-cam-76/3\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry azureaihacka6d64e0ee.azurecr.io\n",
      "Logging into Docker registry azureaihacka6d64e0ee.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM azureaihacka6d64e0ee.azurecr.io/azureml/azureml_81db9aab80b622dc2fe2baa6f684293d\n",
      " ---> f65b3ea99657\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 198f580a7b49\n",
      "Step 3/5 : COPY model_config_map.json /var/azureml-app/model_config_map.json\n",
      " ---> d84de580db61\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpxjwe_u7v.py' /var/azureml-app/main.py\n",
      " ---> Running in 067973b15d39\n",
      " ---> 81ed400296c9\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 875104d801ca\n",
      " ---> 6e79bb0569cc\n",
      "Successfully built 6e79bb0569cc\n",
      "Successfully tagged local-deploy:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:a1a8876659b6e69971dd8dbedad87e8f815f0b206ce1856acae4ef32512ab4a9 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:32869\n"
     ]
    }
   ],
   "source": [
    "deploy_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model as Webservice on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_to_cloud()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the service "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"prediction\": [{\"time\": \"2019-09-09T22:30:00-06:00\", \"count\": 11.187052726745605}, {\"time\": \"2019-09-09T22:45:00-06:00\", \"count\": 11.339231491088867}, {\"time\": \"2019-09-09T23:00:00-06:00\", \"count\": 12.544694900512695}, {\"time\": \"2019-09-09T23:15:00-06:00\", \"count\": 14.295623779296875}, {\"time\": \"2019-09-09T23:30:00-06:00\", \"count\": 13.605803489685059}, {\"time\": \"2019-09-09T23:45:00-06:00\", \"count\": 12.726211547851562}, {\"time\": \"2019-09-10T00:00:00-06:00\", \"count\": 13.35285758972168}, {\"time\": \"2019-09-10T00:15:00-06:00\", \"count\": 13.09186840057373}, {\"time\": \"2019-09-10T00:30:00-06:00\", \"count\": 12.472402572631836}, {\"time\": \"2019-09-10T00:45:00-06:00\", \"count\": 13.82763385772705}, {\"time\": \"2019-09-10T01:00:00-06:00\", \"count\": 13.456625938415527}, {\"time\": \"2019-09-10T01:15:00-06:00\", \"count\": 11.666662216186523}, {\"time\": \"2019-09-10T01:30:00-06:00\", \"count\": 11.363595962524414}, {\"time\": \"2019-09-10T01:45:00-06:00\", \"count\": 14.081496238708496}, {\"time\": \"2019-09-10T02:00:00-06:00\", \"count\": 13.23816204071045}, {\"time\": \"2019-09-10T02:15:00-06:00\", \"count\": 10.667838096618652}, {\"time\": \"2019-09-10T02:30:00-06:00\", \"count\": 11.21358871459961}, {\"time\": \"2019-09-10T02:45:00-06:00\", \"count\": 12.863150596618652}, {\"time\": \"2019-09-10T03:00:00-06:00\", \"count\": 12.865739822387695}, {\"time\": \"2019-09-10T03:15:00-06:00\", \"count\": 13.114631652832031}, {\"time\": \"2019-09-10T03:30:00-06:00\", \"count\": 12.374571800231934}, {\"time\": \"2019-09-10T03:45:00-06:00\", \"count\": 12.06545352935791}, {\"time\": \"2019-09-10T04:00:00-06:00\", \"count\": 12.505194664001465}, {\"time\": \"2019-09-10T04:15:00-06:00\", \"count\": 12.216161727905273}, {\"time\": \"2019-09-10T04:30:00-06:00\", \"count\": 11.825993537902832}, {\"time\": \"2019-09-10T04:45:00-06:00\", \"count\": 12.595727920532227}, {\"time\": \"2019-09-10T05:00:00-06:00\", \"count\": 12.151056289672852}, {\"time\": \"2019-09-10T05:15:00-06:00\", \"count\": 11.683419227600098}, {\"time\": \"2019-09-10T05:30:00-06:00\", \"count\": 11.026778221130371}, {\"time\": \"2019-09-10T05:45:00-06:00\", \"count\": 11.050665855407715}, {\"time\": \"2019-09-10T06:00:00-06:00\", \"count\": 12.118917465209961}, {\"time\": \"2019-09-10T06:15:00-06:00\", \"count\": 12.117634773254395}, {\"time\": \"2019-09-10T06:30:00-06:00\", \"count\": 13.45535945892334}, {\"time\": \"2019-09-10T06:45:00-06:00\", \"count\": 11.842018127441406}, {\"time\": \"2019-09-10T07:00:00-06:00\", \"count\": 12.160648345947266}, {\"time\": \"2019-09-10T07:15:00-06:00\", \"count\": 12.031898498535156}, {\"time\": \"2019-09-10T07:30:00-06:00\", \"count\": 11.975447654724121}, {\"time\": \"2019-09-10T07:45:00-06:00\", \"count\": 12.521583557128906}, {\"time\": \"2019-09-10T08:00:00-06:00\", \"count\": 13.984764099121094}, {\"time\": \"2019-09-10T08:15:00-06:00\", \"count\": 13.709175109863281}, {\"time\": \"2019-09-10T08:30:00-06:00\", \"count\": 13.958501815795898}, {\"time\": \"2019-09-10T08:45:00-06:00\", \"count\": 13.385047912597656}, {\"time\": \"2019-09-10T09:00:00-06:00\", \"count\": 13.486539840698242}, {\"time\": \"2019-09-10T09:15:00-06:00\", \"count\": 10.706954956054688}, {\"time\": \"2019-09-10T09:30:00-06:00\", \"count\": 8.213860511779785}, {\"time\": \"2019-09-10T09:45:00-06:00\", \"count\": 8.915616035461426}, {\"time\": \"2019-09-10T10:00:00-06:00\", \"count\": 10.228007316589355}, {\"time\": \"2019-09-10T10:15:00-06:00\", \"count\": 11.730561256408691}, {\"time\": \"2019-09-10T10:30:00-06:00\", \"count\": 12.375676155090332}, {\"time\": \"2019-09-10T10:45:00-06:00\", \"count\": 15.188993453979492}, {\"time\": \"2019-09-10T11:00:00-06:00\", \"count\": 15.340437889099121}, {\"time\": \"2019-09-10T11:15:00-06:00\", \"count\": 15.095189094543457}, {\"time\": \"2019-09-10T11:30:00-06:00\", \"count\": 13.860550880432129}, {\"time\": \"2019-09-10T11:45:00-06:00\", \"count\": 11.23824691772461}, {\"time\": \"2019-09-10T12:00:00-06:00\", \"count\": 9.081252098083496}, {\"time\": \"2019-09-10T12:15:00-06:00\", \"count\": 9.150620460510254}, {\"time\": \"2019-09-10T12:30:00-06:00\", \"count\": 8.31626033782959}, {\"time\": \"2019-09-10T12:45:00-06:00\", \"count\": 8.582262992858887}, {\"time\": \"2019-09-10T13:00:00-06:00\", \"count\": 8.876548767089844}, {\"time\": \"2019-09-10T13:15:00-06:00\", \"count\": 9.8648042678833}, {\"time\": \"2019-09-10T13:30:00-06:00\", \"count\": 10.064993858337402}, {\"time\": \"2019-09-10T13:45:00-06:00\", \"count\": 11.28570556640625}, {\"time\": \"2019-09-10T14:00:00-06:00\", \"count\": 12.911552429199219}, {\"time\": \"2019-09-10T14:15:00-06:00\", \"count\": 10.022302627563477}, {\"time\": \"2019-09-10T14:30:00-06:00\", \"count\": 9.236949920654297}, {\"time\": \"2019-09-10T14:45:00-06:00\", \"count\": 9.878256797790527}, {\"time\": \"2019-09-10T15:00:00-06:00\", \"count\": 9.406904220581055}, {\"time\": \"2019-09-10T15:15:00-06:00\", \"count\": 9.102518081665039}, {\"time\": \"2019-09-10T15:30:00-06:00\", \"count\": 8.003279685974121}, {\"time\": \"2019-09-10T15:45:00-06:00\", \"count\": 7.760176658630371}, {\"time\": \"2019-09-10T16:00:00-06:00\", \"count\": 6.841605186462402}, {\"time\": \"2019-09-10T16:15:00-06:00\", \"count\": 7.8015031814575195}, {\"time\": \"2019-09-10T16:30:00-06:00\", \"count\": 7.8132710456848145}, {\"time\": \"2019-09-10T16:45:00-06:00\", \"count\": 9.144584655761719}, {\"time\": \"2019-09-10T17:00:00-06:00\", \"count\": 10.17017936706543}, {\"time\": \"2019-09-10T17:15:00-06:00\", \"count\": 8.59485912322998}, {\"time\": \"2019-09-10T17:30:00-06:00\", \"count\": 8.10700511932373}, {\"time\": \"2019-09-10T17:45:00-06:00\", \"count\": 9.937641143798828}, {\"time\": \"2019-09-10T18:00:00-06:00\", \"count\": 9.212162017822266}, {\"time\": \"2019-09-10T18:15:00-06:00\", \"count\": 8.590435028076172}, {\"time\": \"2019-09-10T18:30:00-06:00\", \"count\": 9.344404220581055}, {\"time\": \"2019-09-10T18:45:00-06:00\", \"count\": 9.086370468139648}, {\"time\": \"2019-09-10T19:00:00-06:00\", \"count\": 10.02662467956543}, {\"time\": \"2019-09-10T19:15:00-06:00\", \"count\": 8.555395126342773}, {\"time\": \"2019-09-10T19:30:00-06:00\", \"count\": 8.570402145385742}, {\"time\": \"2019-09-10T19:45:00-06:00\", \"count\": 8.104896545410156}, {\"time\": \"2019-09-10T20:00:00-06:00\", \"count\": 8.408347129821777}, {\"time\": \"2019-09-10T20:15:00-06:00\", \"count\": 8.331934928894043}, {\"time\": \"2019-09-10T20:30:00-06:00\", \"count\": 7.370106220245361}, {\"time\": \"2019-09-10T20:45:00-06:00\", \"count\": 8.682759284973145}, {\"time\": \"2019-09-10T21:00:00-06:00\", \"count\": 8.30240535736084}, {\"time\": \"2019-09-10T21:15:00-06:00\", \"count\": 8.826257705688477}, {\"time\": \"2019-09-10T21:30:00-06:00\", \"count\": 8.462786674499512}, {\"time\": \"2019-09-10T21:45:00-06:00\", \"count\": 9.739130973815918}, {\"time\": \"2019-09-10T22:00:00-06:00\", \"count\": 9.392255783081055}, {\"time\": \"2019-09-10T22:15:00-06:00\", \"count\": 11.122815132141113}], \"historical\": [{\"time\": \"2019-09-09T22:00:00-06:00\", \"count\": 6.5}, {\"time\": \"2019-09-09T21:00:00-06:00\", \"count\": 6.25}, {\"time\": \"2019-09-09T20:00:00-06:00\", \"count\": 5.909090909090909}, {\"time\": \"2019-09-09T19:00:00-06:00\", \"count\": 6.583333333333333}, {\"time\": \"2019-09-09T18:00:00-06:00\", \"count\": 6.666666666666667}, {\"time\": \"2019-09-09T17:00:00-06:00\", \"count\": 8.333333333333334}, {\"time\": \"2019-09-09T14:00:00-06:00\", \"count\": 6.6}, {\"time\": \"2019-09-09T13:00:00-06:00\", \"count\": 4.333333333333333}, {\"time\": \"2019-09-09T12:00:00-06:00\", \"count\": 7.0}, {\"time\": \"2019-09-09T11:00:00-06:00\", \"count\": 7.916666666666667}, {\"time\": \"2019-09-09T10:00:00-06:00\", \"count\": 6.533333333333333}, {\"time\": \"2019-09-09T09:00:00-06:00\", \"count\": 6.875}, {\"time\": \"2019-09-09T08:00:00-06:00\", \"count\": 14.666666666666666}, {\"time\": \"2019-09-09T07:00:00-06:00\", \"count\": 7.3}, {\"time\": \"2019-09-09T06:00:00-06:00\", \"count\": 9.4}, {\"time\": \"2019-09-09T05:00:00-06:00\", \"count\": 11.833333333333334}, {\"time\": \"2019-09-09T04:00:00-06:00\", \"count\": 10.166666666666666}, {\"time\": \"2019-09-09T03:00:00-06:00\", \"count\": 10.25}, {\"time\": \"2019-09-09T02:00:00-06:00\", \"count\": 10.416666666666666}, {\"time\": \"2019-09-09T01:00:00-06:00\", \"count\": 10.083333333333334}, {\"time\": \"2019-09-09T00:00:00-06:00\", \"count\": 11.416666666666666}, {\"time\": \"2019-09-08T23:00:00-06:00\", \"count\": 10.23076923076923}, {\"time\": \"2019-09-08T22:00:00-06:00\", \"count\": 9.846153846153847}, {\"time\": \"2019-09-08T21:00:00-06:00\", \"count\": 11.0}]}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=requests.post('http://localhost:32869/score',json={\n",
    "    'cameraId':76,\n",
    "\t'steps':96\n",
    "})\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
